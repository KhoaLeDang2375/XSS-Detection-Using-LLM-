{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1018162,"sourceType":"datasetVersion","datasetId":559858},{"sourceId":13550052,"sourceType":"datasetVersion","datasetId":8602178}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. T·∫£i th∆∞ vi·ªán c·∫ßn thi·∫øt","metadata":{}},{"cell_type":"code","source":"# ==================== CELL 1: Optimized Installation ====================\nprint(\" Installing dependencies...\")\n\n# G·ª° c√†i ƒë·∫∑t c≈©\n!pip uninstall -y accelerate transformers peft -q\n\n# C·∫≠p nh·∫≠t pip\n# !pip install -q --upgrade pip\n\n# C√†i ƒë·∫∑t phi√™n b·∫£n t∆∞∆°ng th√≠ch\n!pip install -q \\\n    \"transformers==4.39.3\" \\\n    \"datasets==2.16.1\" \\\n    \"accelerate==0.27.2\" \\\n    \"evaluate==0.4.1\" \\\n    \"scikit-learn==1.3.2\"\n\nprint(\" Installation completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T01:32:56.044232Z","iopub.execute_input":"2025-12-10T01:32:56.044463Z","iopub.status.idle":"2025-12-10T01:34:23.631418Z","shell.execute_reply.started":"2025-12-10T01:32:56.044437Z","shell.execute_reply":"2025-12-10T01:34:23.630709Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ==================== CELL 2: Suppress Warnings ====================\nimport warnings\nimport os\nimport logging\n\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'  # Tr√°nh warning\nlogging.getLogger('tensorflow').setLevel(logging.ERROR)\n\nprint(\" Warnings suppressed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T01:34:23.633109Z","iopub.execute_input":"2025-12-10T01:34:23.633357Z","iopub.status.idle":"2025-12-10T01:34:23.638710Z","shell.execute_reply.started":"2025-12-10T01:34:23.633335Z","shell.execute_reply":"2025-12-10T01:34:23.637936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== CELL 3: Import Libraries ====================\nimport pandas as pd\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc  # Garbage collector\nfrom tqdm.auto import tqdm\n\n# sklearn\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import (\n    accuracy_score, precision_recall_fscore_support, confusion_matrix,\n    classification_report, roc_curve, roc_auc_score\n)\n\n# Hugging Face\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    EarlyStoppingCallback,\n    DataCollatorWithPadding\n)\nprint(\" Importing libraries...\")\n\nfrom datasets import Dataset, DatasetDict\n\n# Ki·ªÉm tra thi·∫øt b·ªã\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\n  Using device: {device}\")\n\nif torch.cuda.is_available():\n    print(f\" GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\" Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n    torch.cuda.empty_cache()\nelse:\n    print(\"  GPU not available, using CPU\")\n\nprint(\"\\nAll libraries imported successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T01:34:23.639521Z","iopub.execute_input":"2025-12-10T01:34:23.639762Z","iopub.status.idle":"2025-12-10T01:34:44.027211Z","shell.execute_reply.started":"2025-12-10T01:34:23.639742Z","shell.execute_reply":"2025-12-10T01:34:44.026520Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. T·∫°o l·ªõp  XSSDataProcessor","metadata":{}},{"cell_type":"code","source":"# ==================== CELL 4: Optimized Data Processor ====================\nclass XSSDataProcessor:\n    \"\"\"\n    X·ª≠ l√Ω t·∫•t c·∫£ vi·ªác t·∫£i, tƒÉng c∆∞·ªùng v√† chu·∫©n b·ªã d·ªØ li·ªáu.\n    Version t·ªëi ∆∞u v·ªõi augmentation th√¥ng minh h∆°n.\n    \"\"\"\n    def __init__(self):\n        print(\"Kh·ªüi t·∫°o XSSDataProcessor.\")\n\n   \n\n    def prepare_dataset(self, train_df, test_df, val_size=0.1, random_state=42):\n        \"\"\"\n        Chu·∫©n b·ªã dataset t·ª´ c√°c t·∫≠p train v√† test ƒë√£ chia s·∫µn, sau ƒë√≥ chia t·∫≠p train th√†nh Train/Validation.\n    \n        Args:\n            train_df (pd.DataFrame): DataFrame ch·ª©a d·ªØ li·ªáu hu·∫•n luy·ªán.\n            test_df (pd.DataFrame): DataFrame ch·ª©a d·ªØ li·ªáu ki·ªÉm th·ª≠.\n            val_size (float): T·ª∑ l·ªá ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c t√°ch ra l√†m t·∫≠p Validation (t·ª´ train_df).\n            random_state (int): Seed ng·∫´u nhi√™n ƒë·ªÉ ƒë·∫£m b·∫£o kh·∫£ nƒÉng t√°i l·∫≠p.\n    \n        Returns:\n            tuple: (dataset, test_df) v·ªõi dataset l√† DatasetDict (ch·ª©a 'train', 'validation', 'test') \n                   v√† test_df l√† t·∫≠p ki·ªÉm th·ª≠ ban ƒë·∫ßu.\n        \"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\" CHU·∫®N B·ªä D·ªÆ LI·ªÜU T·ª™ T·∫¨P ƒê√É CHIA\")\n        print(\"=\"*60)\n        \n\n    \n        # 2. Chia Train th√†nh Train v√† Validation\n        train_df, val_df = train_test_split(\n            train_df,\n            test_size=0.1,\n            random_state=random_state,\n        )\n    \n        print(f\"\\n T·∫≠p Train (sau khi chia val): {len(train_df)} m·∫´u\")\n        print(f\" T·∫≠p Validation: {len(val_df)} m·∫´u\")\n        print(f\" T·∫≠p Test (ƒë·∫ßu v√†o): {len(test_df)} m·∫´u\")\n    \n        # 3. Chuy·ªÉn ƒë·ªïi sang Hugging Face Dataset\n        dataset = DatasetDict({\n            'train': Dataset.from_pandas(train_df.reset_index(drop=True)),\n            'validation': Dataset.from_pandas(val_df.reset_index(drop=True)),\n            'test': Dataset.from_pandas(test_df.reset_index(drop=True))\n        })\n        \n        # 4. In th·ªëng k√™ nh√£n cho t·∫≠p Test (ƒë·∫£m b·∫£o t√≠nh c√¥ng b·∫±ng)\n        print(\"\\n Th·ªëng k√™ nh√£n t·∫≠p Test:\")\n        try:\n            test_stats = test_df['label'].value_counts(normalize=True).mul(100).round(2)\n            print(test_stats.to_string())\n        except KeyError:\n            print(\"Kh√¥ng t√¨m th·∫•y c·ªôt 'label' ƒë·ªÉ th·ªëng k√™.\")\n    \n        return dataset, test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T01:34:44.027910Z","iopub.execute_input":"2025-12-10T01:34:44.028533Z","iopub.status.idle":"2025-12-10T01:34:44.036435Z","shell.execute_reply.started":"2025-12-10T01:34:44.028490Z","shell.execute_reply":"2025-12-10T01:34:44.035535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n\n# ==================== CELL 5: Optimized XSS Detector ====================\nclass XSSDetector:\n    \"\"\"\n    Version t·ªëi ∆∞u v·ªõi better memory management v√† batch inference\n    \"\"\"\n    def __init__(self, model_name, device, max_length=128):\n        print(\"\\n\" + \"=\"*60)\n        print(f\" KH·ªûI T·∫†O XSS DETECTOR V·ªöI MODEL: {model_name}\")\n        print(\"=\"*60)\n        \n        self.model_name = model_name\n        self.device = device\n        self.max_length = max_length\n        self.trainer = None\n        self.roc_auc = 0.0\n        \n        # T·∫£i tokenizer v√† model\n        print(f\"ƒêang t·∫£i tokenizer cho: {self.model_name}...\")\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        \n        # Th√™m pad token n·∫øu kh√¥ng c√≥ (cho GPT2, CodeBERT)\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n        \n        print(f\"ƒêang t·∫£i m√¥ h√¨nh cho: {self.model_name}...\")\n        self.model = AutoModelForSequenceClassification.from_pretrained(\n            self.model_name,\n            num_labels=2,\n            problem_type=\"single_label_classification\",\n            ignore_mismatched_sizes=True  # Important cho m·ªôt s·ªë model\n        )\n        \n        # C·∫•u h√¨nh pad token id cho model\n        self.model.config.pad_token_id = self.tokenizer.pad_token_id\n        self.model.to(self.device)\n        \n        print(f\" Model ƒë√£ t·∫£i: {self.model_name}\")\n        print(f\" T·ªïng s·ªë tham s·ªë: {self.model.num_parameters():,}\")\n        \n        # Clear cache\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n\n    def _tokenize_function(self, examples):\n        \"\"\"H√†m token h√≥a v·ªõi dynamic padding\"\"\"\n        return self.tokenizer(\n            examples['text'],\n            truncation=True,\n            max_length=self.max_length,\n            # B·ªè padding ·ªü ƒë√¢y, s·∫Ω padding ƒë·ªông trong DataCollator\n        )\n\n    def tokenize_dataset(self, dataset):\n        \"\"\"Token h√≥a dataset\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\" TOKEN H√ìA D·ªÆ LI·ªÜU\")\n        print(\"=\"*60)\n        \n        tokenized_dataset = dataset.map(\n            self._tokenize_function,\n            batched=True,\n            remove_columns=['text']  # X√≥a column text ƒë·ªÉ ti·∫øt ki·ªám memory\n        )\n        \n        print(\" Token h√≥a ho√†n t·∫•t\")\n        return tokenized_dataset\n\n    def _compute_metrics(self, eval_pred):\n        \"\"\"T√≠nh to√°n metrics\"\"\"\n        predictions, labels = eval_pred\n        predictions = np.argmax(predictions, axis=1)\n        \n        accuracy = accuracy_score(labels, predictions)\n        precision, recall, f1, _ = precision_recall_fscore_support(\n            labels, predictions, average='binary', zero_division=0\n        )\n        \n        cm = confusion_matrix(labels, predictions)\n        if cm.size == 4:\n            tn, fp, fn, tp = cm.ravel()\n            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n        else:\n            tp = fp = tn = fn = specificity = 0\n        \n        return {\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n            'f1': f1,\n            'specificity': specificity,\n            'tp': int(tp),\n            'fp': int(fp),\n            'tn': int(tn),\n            'fn': int(fn)\n        }\n\n    def train(self, tokenized_dataset, training_args):\n        \"\"\"Hu·∫•n luy·ªán m√¥ h√¨nh\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\" B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN\")\n        print(\"=\"*60 + \"\\n\")\n        \n        # S·ª≠ d·ª•ng DataCollator cho dynamic padding\n        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n        \n        self.trainer = Trainer(\n            model=self.model,\n            args=training_args,\n            train_dataset=tokenized_dataset['train'],\n            eval_dataset=tokenized_dataset['validation'],\n            tokenizer=self.tokenizer,\n            data_collator=data_collator,  # Dynamic padding\n            compute_metrics=self._compute_metrics,\n            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n        )\n        \n        # Clear cache tr∆∞·ªõc khi train\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        \n        train_result = self.trainer.train()\n        \n        print(\"\\n‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!\")\n        print(f\"Th·ªùi gian: {train_result.metrics['train_runtime']:.2f} gi√¢y\")\n        \n        # Clear cache sau khi train\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        gc.collect()\n\n    def evaluate(self, eval_dataset=None):\n        \"\"\"ƒê√°nh gi√° m√¥ h√¨nh\"\"\"\n        if not self.trainer:\n            print(\"L·ªói: M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán.\")\n            return None\n            \n        print(\"\\n\" + \"=\"*60)\n        print(\"ƒê√ÅNH GI√Å M√î H√åNH\")\n        print(\"=\"*60)\n        \n        eval_results = self.trainer.evaluate(eval_dataset=eval_dataset)\n\n        print(\"\\nüìà K·∫øt qu·∫£:\")\n        for key, value in eval_results.items():\n            if key.startswith('eval_'):\n                metric_name = key.replace('eval_', '').upper()\n                if isinstance(value, float):\n                    print(f\"  {metric_name}: {value:.4f}\")\n                else:\n                    print(f\"  {metric_name}: {value}\")\n        \n        return eval_results\n\n    def analyze_performance(self, tokenized_test_dataset):\n        \"\"\"Ph√¢n t√≠ch chi ti·∫øt v·ªõi batch inference\"\"\"\n        if not self.trainer:\n            print(\"L·ªói: M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán.\")\n            return\n            \n        print(\"\\n\" + \"=\"*60)\n        print(\" PH√ÇN T√çCH CHI TI·∫æT\")\n        print(\"=\"*60)\n\n        # Batch prediction (nhanh h∆°n nhi·ªÅu)\n        predictions_output = self.trainer.predict(tokenized_test_dataset)\n        \n        # === L·∫§Y TH·ªúI GIAN SUY LU·∫¨N TEST SET ===\n        inference_time_test = predictions_output.metrics['test_runtime']\n        samples_per_sec = predictions_output.metrics['test_samples_per_second']\n        ms_per_sample = 1000 / samples_per_sec if samples_per_sec > 0 else 0\n        \n        print(f\"\\n‚è± Inference time (test set - {len(tokenized_test_dataset)} samples): {inference_time_test:.3f} gi√¢y\")\n        print(f\"   T·ªëc ƒë·ªô: {samples_per_sec:.1f} m·∫´u/gi√¢y ‚Üí {ms_per_sample:.2f} ms/m·∫´u\")\n        predictions = np.argmax(predictions_output.predictions, axis=1)\n        labels = predictions_output.label_ids\n        probabilities = torch.softmax(\n            torch.tensor(predictions_output.predictions), dim=1\n        ).numpy()\n\n        # Classification Report\n        print(\"\\n Classification Report:\")\n        print(classification_report(\n            labels, predictions,\n            target_names=['Safe', 'XSS'],\n            digits=4,\n            zero_division=0\n        ))\n\n        # Confusion Matrix\n        cm = confusion_matrix(labels, predictions)\n        plt.figure(figsize=(8, 6))\n        sns.heatmap(\n            cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Safe', 'XSS'],\n            yticklabels=['Safe', 'XSS']\n        )\n        plt.title(f'Confusion Matrix - {self.model_name}', fontweight='bold')\n        plt.ylabel('True Label')\n        plt.xlabel('Predicted Label')\n        plt.tight_layout()\n        plt.savefig(f'cm_{self.model_name.replace(\"/\", \"_\")}.png', dpi=300)\n        plt.show()\n\n        # ROC Curve\n        if len(np.unique(labels)) > 1:\n            fpr, tpr, _ = roc_curve(labels, probabilities[:, 1])\n            self.roc_auc = roc_auc_score(labels, probabilities[:, 1])\n\n            plt.figure(figsize=(8, 6))\n            plt.plot(fpr, tpr, color='darkorange', lw=2,\n                    label=f'ROC (AUC = {self.roc_auc:.4f})')\n            plt.plot([0, 1], [0, 1], color='navy', lw=2,\n                    linestyle='--', label='Random')\n            plt.xlim([0.0, 1.0])\n            plt.ylim([0.0, 1.05])\n            plt.xlabel('False Positive Rate')\n            plt.ylabel('True Positive Rate')\n            plt.title(f'ROC Curve - {self.model_name}', fontweight='bold')\n            plt.legend(loc=\"lower right\")\n            plt.grid(alpha=0.3)\n            plt.tight_layout()\n            plt.savefig(f'roc_{self.model_name.replace(\"/\", \"_\")}.png', dpi=300)\n            plt.show()\n        else:\n            print(\" Ch·ªâ c√≥ 1 class, b·ªè qua ROC curve\")\n            self.roc_auc = 0.0\n\n    def save_model(self, output_dir):\n        \"\"\"L∆∞u m√¥ h√¨nh\"\"\"\n        if not self.trainer:\n            print(\"L·ªói: M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán.\")\n            return\n            \n        print(\"\\n\" + \"=\"*60)\n        print(\" ƒêANG L∆ØU M√î H√åNH\")\n        print(\"=\"*60)\n        \n        model_path = f\"{output_dir}/{self.model_name.replace('/', '_')}\"\n        os.makedirs(model_path, exist_ok=True)\n        \n        self.model.save_pretrained(model_path)\n        self.tokenizer.save_pretrained(model_path)\n        \n        print(f\" M√¥ h√¨nh ƒë√£ l∆∞u: {model_path}\")\n        return model_path\n\n    def predict(self, text, show_details=True):\n        \"\"\"D·ª± ƒëo√°n ƒë∆°n l·∫ª\"\"\"\n        inputs = self.tokenizer(\n            text,\n            return_tensors='pt',\n            truncation=True,\n            max_length=self.max_length,\n            padding=True\n        )\n        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n        \n        self.model.eval()\n        with torch.no_grad():\n            outputs = self.model(**inputs)\n            probs = torch.softmax(outputs.logits, dim=1)\n            pred = torch.argmax(probs, dim=1).item()\n            conf = probs[0][pred].item()\n        \n        label = \"üö® XSS\" if pred == 1 else \"‚úÖ SAFE\"\n        \n        if show_details:\n            print(f\"\\nInput: {text[:80]}...\")\n            print(f\"Prediction: {label}\")\n            print(f\"Confidence: {conf:.2%}\")\n            print(\"-\" * 60)\n            \n        return pred, conf, label\n\n    def batch_predict(self, texts, batch_size=32):\n        \"\"\"Batch prediction (nhanh h∆°n nhi·ªÅu) + return th·ªùi gian\"\"\"\n        self.model.eval()\n        all_predictions = []\n        all_confidences = []\n    \n        start_time = time.time()  \n    \n        for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\"):\n            batch_texts = texts[i:i+batch_size]\n            \n            inputs = self.tokenizer(\n                batch_texts,\n                return_tensors='pt',\n                truncation=True,\n                max_length=self.max_length,\n                padding=True\n            )\n            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n            \n            with torch.no_grad():\n                outputs = self.model(**inputs)\n                probs = torch.softmax(outputs.logits, dim=1)\n                preds = torch.argmax(probs, dim=1)\n                confs = probs[range(len(preds)), preds]\n            \n            all_predictions.extend(preds.cpu().numpy())\n            all_confidences.extend(confs.cpu().numpy())\n    \n        end_time = time.time()\n        total_time = end_time - start_time\n        avg_time_per_sample = total_time / len(texts) if len(texts) > 0 else 0\n    \n        print(f\"\\n‚è± T·ªïng th·ªùi gian suy lu·∫≠n: {total_time:.3f} gi√¢y\")\n        print(f\"   Trung b√¨nh / m·∫´u: {avg_time_per_sample*1000:.2f} ms\")\n    \n        return all_predictions, all_confidences, total_time, avg_time_per_sample\n\n    def analyze_errors(self, test_df):\n        \"\"\"Ph√¢n t√≠ch l·ªói v·ªõi batch inference\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\" PH√ÇN T√çCH L·ªñI\")\n        print(\"=\"*60)\n\n        texts = test_df['text'].tolist()\n        true_labels = test_df['label'].tolist()\n        \n        # Batch prediction\n        predictions, confidences, *_ = self.batch_predict(texts)\n        # T√¨m errors\n        errors = []\n        for text, true, pred, conf in zip(texts, true_labels, predictions, confidences):\n            if pred != true:\n                errors.append({\n                    'text': text,\n                    'true': 'XSS' if true == 1 else 'Safe',\n                    'pred': 'XSS' if pred == 1 else 'Safe',\n                    'conf': conf\n                })\n\n        if errors:\n            print(f\"\\n T√¨m th·∫•y {len(errors)} l·ªói:\\n\")\n            for i, err in enumerate(errors[:10], 1):\n                print(f\"{i}. Text: {err['text'][:60]}...\")\n                print(f\"   True: {err['true']} | Pred: {err['pred']} | Conf: {err['conf']:.2%}\\n\")\n        else:\n            print(\"\\nüéâ Kh√¥ng c√≥ l·ªói!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T01:34:44.037746Z","iopub.execute_input":"2025-12-10T01:34:44.038474Z","iopub.status.idle":"2025-12-10T01:34:44.081314Z","shell.execute_reply.started":"2025-12-10T01:34:44.038430Z","shell.execute_reply":"2025-12-10T01:34:44.080543Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. H√†m ch·∫°y th·ª≠ nghi·ªám LLM","metadata":{}},{"cell_type":"code","source":"# ==================== XSS COMPLEX PAYLOAD SUITE ====================\n\nXSS_COMPLEX_SUITE = [\n    # === 1. MULTI-LAYER ENCODING (M√£ h√≥a ƒëa l·ªõp) ===\n    {\"payload\": \"&#x3c;&#x73;&#x63;&#x72;&#x69;&#x70;&#x74;&#x3e;alert(1)&#x3c;&#x2f;&#x73;&#x63;&#x72;&#x69;&#x70;&#x74;&#x3e;\", \"expected\": 1, \"type\": \"html_entity_original\"},\n    {\"payload\": \"%253cscript%253ealert(1)%253c/script%253e\", \"expected\": 1, \"type\": \"double_url_original\"},\n    {\"payload\": \"&lt;script&gt;alert(1)&lt;/script&gt;\", \"expected\": 1, \"type\": \"html_entity_display_original\"},\n    {\"payload\": \"&#x3c;s&#x63;r&#x69;pt&#x3e;alert(1)&#x3c;/s&#x63;r&#x69;pt&#x3e;\", \"expected\": 1, \"type\": \"mixed_hex_entity\"},\n    {\"payload\": \"%25253cscript%25253ealert(1)%25253c/script%25253e\", \"expected\": 1, \"type\": \"triple_url\"},\n\n    # === 2. JS OBFUSCATION (Che gi·∫•u m√£ JavaScript) ===\n    {\"payload\": \"eval(String.fromCharCode(97,108,101,114,116,40,49,41))\", \"expected\": 1, \"type\": \"fromcharcode_original\"},\n    {\"payload\": \"eval(atob('YWxlcnQoMSk='))\", \"expected\": 1, \"type\": \"base64_original\"},\n    {\"payload\": \"setTimeout('alert(1)', 0)\", \"expected\": 1, \"type\": \"settimeout_original\"},\n    {\"payload\": \"window['al'+'ert'](1)\", \"expected\": 1, \"type\": \"window_concat\"},\n    {\"payload\": \"new Function('alert(1)')()\", \"expected\": 1, \"type\": \"new_function\"},\n    {\"payload\": \"alert(`${String.fromCharCode(88,83,83)}`)\", \"expected\": 1, \"type\": \"template_literal_fromcharcode\"},\n\n    # === 3. NULL BYTE & TRUNCATION (Byte Null v√† C·∫Øt x√©n) ===\n    {\"payload\": \"<scr%00ipt>alert(1)</scr%00ipt>\", \"expected\": 1, \"type\": \"null_byte_original\"},\n    {\"payload\": \"<script/src=data:,alert(1)>\", \"expected\": 1, \"type\": \"data_uri_original\"},\n\n    # === 4. EVENT HANDLER & TAG OBFUSCATION (Che gi·∫•u s·ª± ki·ªán v√† Th·∫ª) ===\n    {\"payload\": \"<img src=x onerror=eval('al'+'ert(1)')>\", \"expected\": 1, \"type\": \"string_concat_original\"},\n    {\"payload\": \"<svg/onload=alert`1`>\", \"expected\": 1, \"type\": \"backtick_original\"},\n    {\"payload\": \"<body onpageshow=alert(1)>\", \"expected\": 1, \"type\": \"rare_event_original\"},\n    {\"payload\": \"<input autofocus onfocus=alert(1)>\", \"expected\": 1, \"type\": \"autofocus_onfocus\"},\n    {\"payload\": \"<details open onpointerover=alert(1)>\", \"expected\": 1, \"type\": \"onpointerover\"},\n\n    # === 5. PROTOCOL & CSS (Giao th·ª©c v√† CSS) ===\n    {\"payload\": \"<a href=javascript:alert(1)>click\", \"expected\": 1, \"type\": \"javascript_uri_original\"},\n    {\"payload\": \"<style>@import'javascript:alert(1)'</style>\", \"expected\": 1, \"type\": \"css_import_original\"},\n    {\"payload\": \"<div style=background:url(javascript:alert(1))>\", \"expected\": 1, \"type\": \"css_url_original\"},\n\n    # === 6. DOM-BASED XSS (XSS d·ª±a tr√™n DOM) ===\n    {\"payload\": \"location.href = 'javascript:alert(1)'\", \"expected\": 1, \"type\": \"dom_location_original\"},\n    {\"payload\": \"document.write('<script>alert(1)</script>')\", \"expected\": 1, \"type\": \"document_write_original\"},\n    {\"payload\": \"innerHTML = '<img src=x onerror=alert(1)>'\", \"expected\": 1, \"type\": \"innerhtml_original\"},\n\n    # === 7. WAF BYPASS & MISC (V∆∞·ª£t t∆∞·ªùng l·ª≠a WAF v√† Kh√°c) ===\n    {\"payload\": \"<script>/*!--*/alert(1)//</script>\", \"expected\": 1, \"type\": \"comment_obfuscation_original\"},\n    {\"payload\": \"<scr<script>ipt>alert(1)</scr</script>ipt>\", \"expected\": 1, \"type\": \"tag_break_original\"},\n    {\"payload\": \"<img src onerror=alert(1)>\", \"expected\": 1, \"type\": \"missing_quote_original\"},\n    {\"payload\": \"<script>alert(1)</script>\", \"expected\": 1, \"type\": \"unicode_original\"}, # Th∆∞·ªùng l√† payload c∆° b·∫£n\n    {\"payload\": \"<img src=1 onerror=alert(String.fromCharCode(88,83,83))>\", \"expected\": 1, \"type\": \"fromcharcode_xss_original\"},\n    {\"payload\": \"<img\\tsrc=x onerror=alert(1)>\", \"expected\": 1, \"type\": \"tab_char\"},\n    {\"payload\": \"<a href\\n='javascript:alert(1)'>Click</a>\", \"expected\": 1, \"type\": \"newline_char\"},\n    {\"payload\": \"<iframe src=javascript:alert(1)\", \"expected\": 1, \"type\": \"missing_closing_tag\"},\n\n    # === 8. FALSE POSITIVE TRAPS (SAFE - Expected: 0) (B·∫´y D∆∞∆°ng t√≠nh gi·∫£) ===\n    {\"payload\": \"<div>alert me</div>\", \"expected\": 0, \"type\": \"safe_text_original\"},\n    {\"payload\": \"javascript is cool\", \"expected\": 0, \"type\": \"safe_word_original\"},\n    {\"payload\": \"<img src='logo.png'>\", \"expected\": 0, \"type\": \"safe_img_original\"},\n    {\"payload\": \"onload=loadImage()\", \"expected\": 0, \"type\": \"safe_event_original\"},\n    {\"payload\": \"String.fromCharCode(65)\", \"expected\": 0, \"type\": \"safe_js_original\"},\n    {\"payload\": \"User's feedback: I love this site! <Thank You>\", \"expected\": 0, \"type\": \"safe_mixed_text\"},\n    {\"payload\": \"The product cost is 123.45$ (USD)\", \"expected\": 0, \"type\": \"safe_currency\"},\n    {\"payload\": \"<p>This is a paragraph.</p>\", \"expected\": 0, \"type\": \"safe_html_tag\"},\n    {\"payload\": \"<a href=\\\"/products/item?id=123\\\">View Item</a>\", \"expected\": 0, \"type\": \"safe_link_absolute\"},\n    {\"payload\": \"\", \"expected\": 0, \"type\": \"safe_html_comment\"},\n    {\"payload\": \"A script tag: &lt;script&gt; not run\", \"expected\": 0, \"type\": \"safe_escaped_script\"},\n    {\"payload\": \"The function is called: 'alert(0)'\", \"expected\": 0, \"type\": \"safe_js_in_quote\"},\n    {\"payload\": \"function test(a) { return a + 1; }\", \"expected\": 0, \"type\": \"safe_js_function\"},\n    {\"payload\": \"document.getElementById('data').value\", \"expected\": 0, \"type\": \"safe_dom_access\"},\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T01:34:44.082249Z","iopub.execute_input":"2025-12-10T01:34:44.082604Z","iopub.status.idle":"2025-12-10T01:34:44.099828Z","shell.execute_reply.started":"2025-12-10T01:34:44.082582Z","shell.execute_reply":"2025-12-10T01:34:44.099107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== MAIN EXPERIMENT RUNNER ====================\n\"\"\"\nK·ªãch b·∫£n th·ª±c nghi·ªám XSS Detection:\n1. SCENARIO 1: Train tr√™n RAW data (3 LLMs + Logistic Regression)\n2. SCENARIO 2: Train tr√™n AUGMENTED data (3 LLMs only)\n3. ƒê√°nh gi√° tr√™n test set v√† complex payloads cho t·∫•t c·∫£ models\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport time\nimport json\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n# ==================== EXPERIMENT CONFIGURATIONS ====================\nMODELS_LLM = [\n    \"distilbert-base-uncased\",\n    \"roberta-base\",\n    \"microsoft/codebert-base\"\n]\n\nDATA_CONFIG = {\n    \"raw_train\": \"/kaggle/input/xss-dataset/train.csv\",\n    \"augmented_train\": \"/kaggle/input/xss-dataset/train_agumented.csv\",\n    \"test\": \"/kaggle/input/xss-dataset/test.csv\"\n}\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nMAX_LENGTH = 128\nRESULTS_DIR = './experiment_results'\n\n# ==================== EXPERIMENT TRACKER ====================\nclass ExperimentTracker:\n    def __init__(self):\n        self.results = {}\n\n    def log(self, scenario, model_name, data_type, \n             test_metrics, payload_metrics, \n             train_time=None, \n             inference_test_s=None, inference_test_ms_per_sample=None,\n             inference_payload_s=None, inference_payload_ms_per_sample=None):\n        \n        key = f\"{model_name.split('/')[-1]}_{data_type}\"  # ƒë·∫πp h∆°n: codebert-base_augmented\n        if scenario not in self.results:\n            self.results[scenario] = {}\n            \n        self.results[scenario][key] = {\n            \"test_acc\": round(test_metrics.get(\"accuracy\",0), 4),\n            \"test_f1\": round(test_metrics.get(\"f1\",0), 4),\n            \"payload_acc\": round(payload_metrics.get(\"accuracy\",0), 4),\n            \"payload_f1\": round(payload_metrics.get(\"f1\",0), 4),\n            \"train_time_s\": round(train_time, 1) if train_time else None,\n            \"inf_test_s\": round(inference_test_s, 3) if inference_test_s else None,\n            \"inf_test_ms\": round(inference_test_ms_per_sample, 2) if inference_test_ms_per_sample else None,\n            \"inf_payload_s\": round(inference_payload_s, 3) if inference_payload_s else None,\n            \"inf_payload_ms\": round(inference_payload_ms_per_sample, 2) if inference_payload_ms_per_sample else None,\n        }\n    def log_result(self, scenario, model_name, data_type, metrics):\n        \"\"\"L∆∞u k·∫øt qu·∫£ th·ª±c nghi·ªám\"\"\"\n        key = f\"{model_name}_{data_type}\"\n        if scenario not in self.results:\n            self.results[scenario] = {}\n        self.results[scenario][key] = metrics\n    def save(self, path=\"final_experiment_results.json\"):\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(self.results, f, indent=2, ensure_ascii=False)\n        print(f\"\\nƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {path}\")\n    def print_summary(self):\n        print(\"\\n\" + \"=\"*120)\n        print(\"T√ìM T·∫ÆT K·∫æT QU·∫¢ TH·ª∞C NGHI·ªÜM (bao g·ªìm th·ªùi gian suy lu·∫≠n)\")\n        print(\"=\"*120)\n        print(f\"{'Model':<30} {'Data':<12} {'Test Acc':<10} {'Test F1':<10} {'Payload Acc':<12} {'Payload F1':<11} {'Train(s)':<10} {'Inf Test(s)':<12} {'ms/sample':<10} {'Inf Payload(s)':<10}\")\n        print(\"-\" * 120)\n        for scenario, models in self.results.items():\n            for name, m in models.items():\n                print(\n                f\"{name:<30} {name.split('_')[-1]:<12}\"\n                f\"{m['test_acc']:<10.4f} {m['test_f1']:<10.4f} \"\n                f\"{m['payload_acc']:<12.4f} {m['payload_f1']:<11.4f} \"\n                f\"{m['train_time_s']:<10} {m['inf_test_s']:<12} \"\n                f\"{m['inf_test_ms']:<10} {m['inf_payload_s']:<10}\"\n            )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T01:34:44.101704Z","iopub.execute_input":"2025-12-10T01:34:44.102001Z","iopub.status.idle":"2025-12-10T01:34:44.119823Z","shell.execute_reply.started":"2025-12-10T01:34:44.101984Z","shell.execute_reply":"2025-12-10T01:34:44.119073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== LOGISTIC REGRESSION TRAINER ====================\ndef train_logistic_regression(X_train, y_train, X_test, y_test, payloads_df, tracker):\n    \"\"\"Train v√† ƒë√°nh gi√° Logistic Regression\"\"\"\n    from sklearn.feature_extraction.text import TfidfVectorizer\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.pipeline import Pipeline\n    from sklearn.model_selection import GridSearchCV\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\" TRAINING LOGISTIC REGRESSION (RAW DATA)\")\n    print(\"=\"*80)\n    \n    # Pipeline\n    pipe = Pipeline([\n        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,2))),\n        ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', solver='saga'))\n    ])\n    \n    # Grid Search\n    param_grid = [\n        {'clf__penalty': ['l1'], 'clf__C': [0.01, 0.1, 1]},\n        {'clf__penalty': ['l2'], 'clf__C': [0.01, 0.1, 1]},\n    ]\n    \n    grid = GridSearchCV(pipe, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n    \n    # Training\n    start = time.time()\n    grid.fit(X_train, y_train)\n    train_time = time.time() - start\n    \n    print(f\"\\n Training time: {train_time:.2f}s\")\n    print(f\"Best params: {grid.best_params_}\")\n    \n    # Evaluate on test set\n    y_test_pred = grid.predict(X_test)\n    test_metrics = {\n        'accuracy': accuracy_score(y_test, y_test_pred),\n        'report': classification_report(y_test, y_test_pred, output_dict=True),\n        'f1': classification_report(y_test, y_test_pred, output_dict=True)['weighted avg']['f1-score']\n    }\n    \n    print(f\"\\n Test Set Performance:\")\n    print(f\"   Accuracy: {test_metrics['accuracy']:.4f}\")\n    print(f\"   F1-Score: {test_metrics['f1']:.4f}\")\n    \n    # Evaluate on complex payloads\n    X_payloads = payloads_df['text']\n    y_payloads = payloads_df['label']\n    y_payload_pred = grid.predict(X_payloads)\n    \n    payload_metrics = {\n        'accuracy': accuracy_score(y_payloads, y_payload_pred),\n        'report': classification_report(y_payloads, y_payload_pred, output_dict=True),\n        'f1': classification_report(y_payloads, y_payload_pred, output_dict=True)['weighted avg']['f1-score']\n    }\n    \n    print(f\"\\n Complex Payloads Performance:\")\n    print(f\"   Accuracy: {payload_metrics['accuracy']:.4f}\")\n    print(f\"   F1-Score: {payload_metrics['f1']:.4f}\")\n    \n    # Log results\n    tracker.log_result('scenario1_raw', 'LogisticRegression', 'combined', {\n        'test': test_metrics,\n        'payload': payload_metrics,\n        'train_time': train_time\n    })\n    \n    return grid.best_estimator_\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T01:34:44.120636Z","iopub.execute_input":"2025-12-10T01:34:44.120847Z","iopub.status.idle":"2025-12-10T01:34:44.138042Z","shell.execute_reply.started":"2025-12-10T01:34:44.120830Z","shell.execute_reply":"2025-12-10T01:34:44.137418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==================== TH√äM IMPORT N·∫æU CH∆ØA C√ì ====================\nimport time\nimport json\nimport os\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score\nfrom datasets import Dataset, DatasetDict\n\n\n# ==================== MAIN EXPERIMENT (ƒê√É CH·ªàNH S·ª¨A HO√ÄN CH·ªàNH) ====================\ndef main():\n    print(\"\\n\" + \"=\"*90)\n    print(\"XSS DETECTION EXPERIMENT\")\n    print(\"=\"*90)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    processor = XSSDataProcessor()\n    tracker = ExperimentTracker()\n\n    # Load d·ªØ li·ªáu\n    train_raw_df = pd.read_csv(\"/kaggle/input/xss-dataset/train.csv\")\n    train_aug_df = pd.read_csv(\"/kaggle/input/xss-dataset/train_agumented.csv\")  \n    test_df = pd.read_csv(\"/kaggle/input/xss-dataset/test.csv\")\n\n    # Complex payload suite\n    payloads_df = pd.DataFrame([\n        { \"text\": item[\"payload\"], \"label\": item[\"expected\"] } for item in XSS_COMPLEX_SUITE\n    ])\n\n    print(f\"Raw train: {len(train_raw_df):,} | Augmented train: {len(train_aug_df):,} | Test: {len(test_df):,}\")\n\n    # ===============================================\n    # SCENARIO 1: RAW DATA (Logistic + 3 LLM)\n    # ===============================================\n    print(\"\\n\" + \"=\"*90)\n    print(\"SCENARIO 1: TRAINING ON RAW DATA\")\n    print(\"=\"*90)\n\n    # Logistic Regression\n    print(\"\\nTraining Logistic Regression...\")\n    log_model = train_logistic_regression(\n        train_raw_df[\"text\"], train_raw_df[\"label\"],\n        test_df[\"text\"], test_df[\"label\"],\n        payloads_df, tracker\n    )\n\n    # 3 LLM tr√™n raw data\n    for model_name in MODELS_LLM:\n        print(f\"\\nTraining {model_name} tr√™n RAW data...\")\n        start_time = time.time()\n\n        dataset, _ = processor.prepare_dataset(train_raw_df.copy(), test_df.copy())\n\n        detector = XSSDetector(model_name=model_name, device=device, max_length=128)\n\n        tokenized = detector.tokenize_dataset(dataset)\n\n        training_args = TrainingArguments(\n            output_dir=f\"./results/{model_name}_raw\",\n            evaluation_strategy=\"epoch\",\n            save_strategy=\"epoch\",\n            learning_rate=3e-5,\n            per_device_train_batch_size=32,\n            per_device_eval_batch_size=64,\n            num_train_epochs=3,\n            weight_decay=0.01,\n            load_best_model_at_end=True,\n            metric_for_best_model=\"f1\",\n            greater_is_better=True,\n            save_total_limit=2,\n            fp16=True,\n            report_to=\"none\",\n            logging_steps=50,\n            warmup_steps=100,\n        )\n\n        detector.train(tokenized, training_args)\n\n        # ƒê√°nh gi√° tr√™n test set\n        test_results = detector.evaluate(eval_dataset=tokenized[\"test\"])\n\n        print(\"\\nƒêang ƒëo th·ªùi gian suy lu·∫≠n + t√≠nh metrics tr√™n test set...\")\n        predict_output = detector.trainer.predict(tokenized[\"test\"])\n        \n        # L·∫•y metrics t·ª´ predict (c√≥ compute_metrics n√™n s·∫Ω c√≥ test_accuracy, test_f1)\n        test_accuracy = predict_output.metrics.get('test_accuracy', 0.0)\n        test_f1       = predict_output.metrics.get('test_f1', 0.0)\n        \n        # Th·ªùi gian suy lu·∫≠n test set\n        inference_test_s = predict_output.metrics['test_runtime']\n        ms_per_sample_test = 1000 / predict_output.metrics['test_samples_per_second']\n        \n        print(f\"‚úÖ Test set: Acc = {test_accuracy:.4f}, F1 = {test_f1:.4f}\")\n        print(f\"   Inference time: {inference_test_s:.3f}s ‚Üí {ms_per_sample_test:.2f} ms/m·∫´u\")\n\n        # V·∫´n ch·∫°y analyze_performance ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì (n√≥ predict l·∫°i l·∫ßn n·ªØa nh∆∞ng ch·ªâ m·∫•t ~2 gi√¢y)\n        detector.analyze_performance(tokenized[\"test\"])\n\n        # ==================== COMPLEX PAYLOADS ====================\n        print(\"\\n\" + \"=\"*80)\n        print(f\"ƒê√ÅNH GI√Å TR√äN COMPLEX PAYLOAD SUITE {len(XSS_COMPLEX_SUITE)} payload\")\n        print(\"=\"*80)\n\n        # Chuy·ªÉn payloads_df th√†nh HuggingFace Dataset\n        payload_dataset = Dataset.from_pandas(payloads_df.reset_index(drop=True))\n\n        # Tokenize gi·ªëng h·ªát train/test\n        tokenized_payload = payload_dataset.map(\n            detector._tokenize_function, batched=True, remove_columns=['text']\n        )\n\n        tokenized_payload.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n\n        # D√πng trainer.predict ‚Üí c√≥ ƒë·∫ßy ƒë·ªß metrics + th·ªùi gian + confusion matrix + ROC t·ª± ƒë·ªông!\n        payload_predict_output = detector.trainer.predict(tokenized_payload)\n\n        payload_accuracy = payload_predict_output.metrics['test_accuracy']\n        payload_f1       = payload_predict_output.metrics['test_f1']\n        payload_time_s   = payload_predict_output.metrics['test_runtime']\n        payload_ms       = 1000 / payload_predict_output.metrics['test_samples_per_second']\n\n        print(f\"Complex Payload Results ‚Üí Acc: {payload_accuracy:.4f} | F1: {payload_f1:.4f}\")\n        print(f\" Inference time {len(XSS_COMPLEX_SUITE)}: {payload_time_s:.3f}s ‚Üí {payload_ms:.2f} ms/m·∫´u\")\n\n        # T·ª∞ ƒê·ªòNG v·∫Ω Confusion Matrix + ROC Curve cho payload (l∆∞u ·∫£nh v·ªõi t√™n ri√™ng)\n        print(\"\\nƒêang v·∫Ω Confusion Matrix & ROC cho Complex Payload Suite...\")\n        old_model_name = detector.model_name  # backup t√™n model\n        detector.model_name = f\"{model_name.split('/')[-1]}_on_payload\"  # ƒë·ªïi t·∫°m t√™n ƒë·ªÉ l∆∞u ·∫£nh kh√°c\n        detector.analyze_performance(tokenized_payload)  # s·∫Ω l∆∞u cm_..._on_payload.png v√† roc_..._on_payload.png\n        detector.model_name = old_model_name  # tr·∫£ l·∫°i t√™n g·ªëc\n\n        # Ph√¢n t√≠ch l·ªói chi ti·∫øt (in ra payload n√†o b·ªã sai)\n        detector.analyze_errors(payloads_df)\n\n        # ==================== LOG V√ÄO TRACKER (C·∫¨P NH·∫¨T CH√çNH X√ÅC) ====================\n        tracker.log(\n            scenario=\"scenario1_raw\" if \"raw\" in training_args.output_dir else \"scenario2_augmented\",\n            model_name=model_name,\n            data_type=\"raw\" if \"raw\" in training_args.output_dir else \"augmented\",\n            test_metrics={\"accuracy\": test_accuracy, \"f1\": test_f1},\n            payload_metrics={\"accuracy\": payload_accuracy, \"f1\": payload_f1},\n            train_time=time.time() - start_time,\n            inference_test_s=inference_test_s,\n            inference_test_ms_per_sample=ms_per_sample_test,\n            inference_payload_s=payload_time_s,\n            inference_payload_ms_per_sample=payload_ms\n        )\n\n        # L∆∞u model t·ªët nh·∫•t\n        detector.save_model(\"./saved_models\")\n\n        del detector, tokenized\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    # ===============================================\n    # SCENARIO 2: AUGMENTED DATA (ch·ªâ 3 LLM)\n    # ===============================================\n    print(\"\\n\" + \"=\"*90)\n    print(\"SCENARIO 2: TRAINING ON AUGMENTED DATA (LLM only)\")\n    print(\"=\"*90)\n\n    for model_name in MODELS_LLM:\n        print(f\"\\nTraining {model_name} tr√™n AUGMENTED data...\")\n        start_time = time.time()\n\n        dataset, _ = processor.prepare_dataset(train_aug_df.copy(), test_df.copy())\n\n        detector = XSSDetector(model_name=model_name, device=device, max_length=128)\n\n        tokenized = detector.tokenize_dataset(dataset)\n\n        training_args = TrainingArguments(\n            output_dir=f\"./results/{model_name}_augmented\",\n            evaluation_strategy=\"epoch\",\n            save_strategy=\"epoch\",\n            learning_rate=3e-5,\n            per_device_train_batch_size=32,\n            per_device_eval_batch_size=64,\n            num_train_epochs=3,\n            weight_decay=0.01,\n            load_best_model_at_end=True,\n            metric_for_best_model=\"f1\",\n            greater_is_better=True,\n            save_total_limit=2,\n            fp16=True,\n            report_to=\"none\",\n        )\n\n        detector.train(tokenized, training_args)\n\n        test_results = detector.evaluate(eval_dataset=tokenized[\"test\"])\n        print(\"\\nƒêang ƒëo th·ªùi gian suy lu·∫≠n + t√≠nh metrics tr√™n test set...\")\n        predict_output = detector.trainer.predict(tokenized[\"test\"])\n        \n        # L·∫•y metrics t·ª´ predict (c√≥ compute_metrics n√™n s·∫Ω c√≥ test_accuracy, test_f1)\n        test_accuracy = predict_output.metrics.get('test_accuracy', 0.0)\n        test_f1       = predict_output.metrics.get('test_f1', 0.0)\n        \n        # Th·ªùi gian suy lu·∫≠n test set\n        inference_test_s = predict_output.metrics['test_runtime']\n        ms_per_sample_test = 1000 / predict_output.metrics['test_samples_per_second']\n        \n        print(f\"‚úÖ Test set: Acc = {test_accuracy:.4f}, F1 = {test_f1:.4f}\")\n        print(f\"   Inference time: {inference_test_s:.3f}s ‚Üí {ms_per_sample_test:.2f} ms/m·∫´u\")\n\n        # V·∫´n ch·∫°y analyze_performance ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì (n√≥ predict l·∫°i l·∫ßn n·ªØa nh∆∞ng ch·ªâ m·∫•t ~2 gi√¢y)\n        detector.analyze_performance(tokenized[\"test\"])\n        \n        # ==================== COMPLEX PAYLOADS ====================\n        print(\"\\n\" + \"=\"*80)\n        print(f\"ƒê√ÅNH GI√Å TR√äN COMPLEX PAYLOAD SUITE{len(XSS_COMPLEX_SUITE)} payload\")\n        print(\"=\"*80)\n\n        # Chuy·ªÉn payloads_df th√†nh HuggingFace Dataset\n        payload_dataset = Dataset.from_pandas(payloads_df.reset_index(drop=True))\n\n        # Tokenize gi·ªëng h·ªát train/test\n        tokenized_payload = payload_dataset.map(\n            detector._tokenize_function, batched=True, remove_columns=['text']\n        )\n\n        tokenized_payload.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n\n        # D√πng trainer.predict ‚Üí c√≥ ƒë·∫ßy ƒë·ªß metrics + th·ªùi gian + confusion matrix + ROC t·ª± ƒë·ªông!\n        payload_predict_output = detector.trainer.predict(tokenized_payload)\n\n        payload_accuracy = payload_predict_output.metrics['test_accuracy']\n        payload_f1       = payload_predict_output.metrics['test_f1']\n        payload_time_s   = payload_predict_output.metrics['test_runtime']\n        payload_ms       = 1000 / payload_predict_output.metrics['test_samples_per_second']\n\n        print(f\"Complex Payload Results ‚Üí Acc: {payload_accuracy:.4f} | F1: {payload_f1:.4f}\")\n        print(f\" Inference time (22 payloads): {payload_time_s:.3f}s ‚Üí {payload_ms:.2f} ms/m·∫´u\")\n\n        # T·ª∞ ƒê·ªòNG v·∫Ω Confusion Matrix + ROC Curve cho payload (l∆∞u ·∫£nh v·ªõi t√™n ri√™ng)\n        print(\"\\nƒêang v·∫Ω Confusion Matrix & ROC cho Complex Payload Suite...\")\n        old_model_name = detector.model_name  # backup t√™n model\n        detector.model_name = f\"{model_name.split('/')[-1]}_on_payload\"  # ƒë·ªïi t·∫°m t√™n ƒë·ªÉ l∆∞u ·∫£nh kh√°c\n        detector.analyze_performance(tokenized_payload)  # s·∫Ω l∆∞u cm_..._on_payload.png v√† roc_..._on_payload.png\n        detector.model_name = old_model_name  # tr·∫£ l·∫°i t√™n g·ªëc\n\n        # Ph√¢n t√≠ch l·ªói chi ti·∫øt (in ra payload n√†o b·ªã sai)\n        detector.analyze_errors(payloads_df)\n\n        # ==================== LOG V√ÄO TRACKER (C·∫¨P NH·∫¨T CH√çNH X√ÅC) ====================\n        tracker.log(\n            scenario=\"scenario1_raw\" if \"raw\" in training_args.output_dir else \"scenario2_augmented\",\n            model_name=model_name,\n            data_type=\"raw\" if \"raw\" in training_args.output_dir else \"augmented\",\n            test_metrics={\"accuracy\": test_accuracy, \"f1\": test_f1},\n            payload_metrics={\"accuracy\": payload_accuracy, \"f1\": payload_f1},\n            train_time=time.time() - start_time,\n            inference_test_s=inference_test_s,\n            inference_test_ms_per_sample=ms_per_sample_test,\n            inference_payload_s=payload_time_s,\n            inference_payload_ms_per_sample=payload_ms\n        )\n        detector.save_model(\"./saved_models\")\n        del detector, tokenized\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    # ===============================================\n    # K·∫æT QU·∫¢ CU·ªêI\n    # ===============================================\n    # tracker.print_summary()\n    # tracker.save(\"final_experiment_results_2025.json\")\n\n    print(\"\\nHO√ÄN T·∫§T TH·ª∞C NGHI·ªÜM! T·∫•t c·∫£ model ƒë√£ ƒë∆∞·ª£c l∆∞u trong ./saved_models\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-10T01:34:44.138921Z","iopub.execute_input":"2025-12-10T01:34:44.139195Z","iopub.status.idle":"2025-12-10T02:27:10.811211Z","shell.execute_reply.started":"2025-12-10T01:34:44.139177Z","shell.execute_reply":"2025-12-10T02:27:10.810552Z"}},"outputs":[],"execution_count":null}]}